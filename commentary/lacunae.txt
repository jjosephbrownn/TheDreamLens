<h1 class = "miscTitle">Lacunae: Appendices</h1>

<p>These appendices analyse and explain some of the details of the site’s functionality.  Sections are referenced in the commentary thus: <b>Section 1.1.</b>  To be found here also are references specific to the code used (also included within the JavaScript files themselves)</p>
<p>This website was written in JavaScript (JS), P5.js which is an implementation of Processing in JS, and P5.sound, a P5 library which uses the JS WebAudio API.</p>
<p>The site is stored in a public GitHub repository which can be accessed <a class = "gitLink" href = "https://github.com/jjosephbrownn/TheDreamLens">here</a>.  This is identical to the code handed in with an additional “readme” file which contextualises the repository.  The third part web app Netlify hosts this repository as a website: the repository is therefore “the website”.  At the top of the repository can be found a time stamp of the last “commit”.  This will display the last time anything was added or changed.  This will display a time before this project’s deadline and will confirm that nothing has been added or changed after the deadline has passed.  The live website cannot be altered without access to the repository and thus a change in the time stamp.</p>

<h2>1 - Functionality </h2>
<h3>1.1 Introductory Remarks</h3>
<p>It is worth mentioning at this point that this website is intentionally obfuscated and difficult to use.  The experience is not user-friendly and at no point is the functionality explained to the visitor.  This site rewards exploration, experimentation and patience.  The longer a visitor spends in the environment the more rewarding the experience will be and the more musical material will be discovered.  This is apparent in two ways: first, the visitor will learn methods of extracting musical expression or uncovering structural functions and alterations; second, the longer the visitor stays in the site, the more musical information is added to various meta-data storages (see <b>Sections 2.3</b> and <b>2.4</b>) and the more instruments/programs are invoked.</p>
<p>This being said, not all of the pages are musical.  We think this is integral to the structural/developmental effect that we aim to create.  Pages exist both in musical and non-musical format depending on the navigation context.  For example, a text-highlighting page may at points trigger a number of musical ideas and at other times be silent.  We aim for this to be a property (revelation?) that reveals itself over time.  To cut the quick, moving between zones (see <b>Section 2.1</b>) invokes musical pages ending in the “zenith” of <b>Tatters</b>.  Choosing to remain within one zone narrows the choice of pages to visual-only material.  We chose this mechanic in order to favour movement and exploration but also to allow the visitor to zoom in on some of the core ideas which form the centre of each zone.  <b>Scatter</b>, as will be explained later, focusses on narrative and fiction meaning that to stay within <b>Scatter</b> strips away some of the subsequent development and allows a more fundamental engagement with the “theme” of fiction by, for example, presenting read-only works of fiction and complete, spoken word recordings.  Further, this allows a polyvalent mode of artistic engagement which turns on the choice to abstract, develop and deconstruct over reification, clarification, and solidification.  Either of which (or both) is fine by us.</p>
<h3>1.2 – Interaction</h3>
<p>Despite foregrounding difficulty and exploration we feel it is necessary to explain some of the basic functions of the site in order to contextualise this work within an academic setting.  Visitors travel between pages by searching for signs that reveal choices of other pages.  These signs are invisible unless rolled over by a mouse.  On some pages, this happens after a randomised time-period; on others a navigation choice is suggest after a number of moves have been made.</p>
<p>The primary interface is the mouse.  This is the main tool and searchlight with which visitors will find their way around the site.  Left and right clicks will trigger different tasks or events as will mouse position and gestures such as mouse-dragging and speed of mouse movement are important variables.  The second interface is the keyboard.  The visitor is sometimes directed to one or the other, as in the case of text writing pages or point and click pages, but at other times these interfaces might not seem the first tool of choice.  Our advice is to try a bit of everything.</p>
<h3>1.3 – System Requirements</h3>
<p>This site will work on all modern browsers, but we recommend Chrome as this was the browser used in development.  Firefox and Safari will also work perfectly.  Internet Explorer is trash.  If you must use it, we recommend using IE11 (at your peril).  The website makes use of hardware graphics card with WebGL APIs in some of the pages (notably the 3D environments).  This is usually enabled by default on most browsers but there is a chance that it is not.  Enabling WebGL is a simple task and only requires some box-ticking in the browser’s settings.  Please consult the appropriate documentation on how to enable WebGL in your browser of choice.</p>
<p>This site requires a hardware mouse!  Laptop trackpads will work to an extent but each browser will respond to left and right clicking differently or, in some cases, not at all!  Likewise, this site was developed for use on a computer and not a phone or tablet.  Touchscreen usage has not been optimised as it goes beyond the scope of this project.</p>

<h2>2 – Structure and Navigation</h2>
<h3>2.1 – Hierarchy and Index</h3
<p>Pages are ordered into three principle levels:<br>
<p class = "pseudo">1.	“template”: visual only, no audio<br>
2.	Audio-visual: template pages with site-specific music interaction<br>
3.	Advanced audio-visual: a page from category two with combined with another sound making engine (see “music machines”)</p>
<p>This hierarchy is striated by four basic aesthetic subcategories</p>
<p class = "pseudo">1.	<b>Scatter</b> – narrative, stories, poetry, fiction, folk song, train of thought<br>
2.	<b>Gather</b> – collection, memory, history, taxonomy, lists<br>
3.	<b>Cartography</b> – mapping, recombination, patterns, ancient history<br>
4.	<b>Repurpose</b> – technology, philosophy, sampling, sound recordings</p>
<p>These are supplemented by a “combination” category <b>Tatters</b> which is the home of the third principle category pages.  Level two contains usually one music making device (or, if more than one, several similar machines).  Level three combines two different sound sources and aesthetic categories and subverts any of the rules learnt by the user concerning interaction.</p>
<p>The final categories are <b>Lacunae</b> and <b>Miscera</b>.  The former contains fixed media pages: web zines, explanatory diagrams and other resources from the building process.  The latter contains the contextual review and this very appendix.</p>

<h3>2.2 - Navigation</h3>
<p>The start page randomly requests one of the level one pages and sets the starting parameters for the various music sources (see Section 2.4 and 3). From here the visitor can start the navigation process through the network of pages.  There are two ways of progressing, both initially hidden from the user.  </p>
<p>Text based pages include a hidden panel that is made visible by hovering the mouse over it.  This panel will randomly display one of two methods for progressing: 1) a simple button below a randomly chosen message that prompts the visitor into moving on (for example “a little to the right” or “around the next corner”); 2) a question with a field for entering an answer.  This latter implies a correct response is required to pass onwards but the program does not parse the input and allows the visitor to progress no matter the input.  These two panels open the main “modal”: a web development term for a floating panel that can be called into existence by, for example, pressing a button.  In this modal is presented the choices for further progression.</p>
<p>“Drawing” pages employ a similar mechanic:  a hidden image element of an arrow is made visible by hovering.  This arrow is randomly placed at the margins of pages and rotated by a random amount of degrees at page load so that it points in different directions.  Clicking on this arrow calls the modal with the same choices as the text pages.
The choice of further progression is mapped thus:</p>

<h3>Fig 1.</h3>
<p class = "pseudo"><b>Scatter / Gather<br>
Gather / Repurpose<br>
Repurpose / Cartography<br>
Cartography / Scatter / Lacunae<br>
Lacunae / Miscera / Tatters<br>
Miscera / Tatters<br>
Scatter / Gather / Tatters</b></p>

<p>Each page offers the chance to move onto the next category or stay within the same space.  The first term in the above series is always the category of the currently active page.  For example if the user clicks on the <b>Lacunae</b> link the choices on the next page will be <b>Lacunae / Miscera / Tatters</b>.  The exceptions are Tatters pages which will offer a return to the beginning. </p> 

<h3>2.3 – Footsteps and exploratory development</h3>
<p>Every time a visitor clicks on a link the data is saved in the browser’s “session storage”.  This is a session specific memory and will remain active and accessible while the tab is open.  If the visitor navigates away from the site and then returns in the same tab the memory will remain active.  The data is only erased if the tab is closed.  A future possibility would be to save this memory within the browser in a more a permanent way but for now we preferred the idea of clearing the chalkboard and returning to a fresh site every time.</p>
<p>This data is saved in a few different ways:</p>
<ul class = "lacList">
<li>Page counting: the browser keeps track of the decisions (for example, four <b>Scatters</b>, two <b>Gathers</b> etc)</li>
<li>Previous choice: the link last clicked which brought the visitor to the current page</li>
<li>Previous page category: the category of the last page from which the visitor navigated.</li>
<li>Melody writing: each category represents a degree of a “normalised” mode.  <b>Scatter</b> is degree 0, <b>Gather</b> is degree 1 and so on.  Each time a link is pressed a degree is added to an array in the session storage.  This can be used to map a melody to a specific mode which is chosen</li>
<li>Mode choice: each link saves a specific mode to interpret this melody (see Section 3)</li>
<li>Mode alteration: after all of the links have been chosen at least once the set of possible modes is changed from major</li> scale modes to minor scale modes.</li>
<li>Keystroke logging: in the <b>Repurpose</b> pages the browser listens and records any typed information into a single string to be used as “interference” in other typing-based pages and loadframes.</li>
<li>Loop increment: pages that use the Lindenmayer system to write melodies (see Section 3) require a number of loops that dictate the length of the eventual “sentence”.  The <b>Cartography</b> link logs the amount time it has been chosen and this number becomes the loop number for writing an L-system syntax.</li>
<li>Loadframe visuals:  While loading the page displays some nice material.  This material is an important “scene setting” device and frames the way in which the visitor might interpret the following page especially after having made a choice the effects of which are obscured.</li>
<ul class = "lacList">
<li><b>Scatter</b> displays cartoons and zines</li>
<li><b>Gather</b> loads quotations from John Masefield’s poem Reynard the Fox or from various Anglo-Saxon poems</li>
<li><b>Cartography</b> loads full page Ordnance Survey Maps</li>
<li><b>Repurpose</b> loads explanatory/poetic images of site’s mechanics</li>
<li><b>Lacunae</b>, <b>Tatters</b> and <b>Miscera</b> make random choices from all of the above categories</li>
</ul>
</ul>
<p>There also exist a few pages which directly ask the user to intervene in the footstep process and will be analysed in <b>Section 2.3.2</b></p>
<p>The result of this data saving is that melodies develop over time and, after a certain cut off point, shift into the distinctive minor key modes.  Musical material is affected in a tangible yet oblique and mysterious fashion by the visitor’s choices.</p>
<h4>2.3.1 – Hidden Data Collection </h4>
<p>This section analyses data that is stored unbeknownst to the visitor.  Session storage saves data to the browser window in key/value pairs (for example: “previousPlace”, “scatter”) meaning that only data that we have specified as important is saved: other details (such as IP address, browser history) are not tracked.</p>
<p>On selecting a next destination the current page stores to session storage the current page category, the new page category (the selected link), a number between 0 and 6 which represents a melody degree, a mode (“dorian” etc), and an incremented value for the number of loops to perform of an L-system (<b>Cartography</b> choices only).  This serves as a global memory which can be accessed by all pages on calling sessionStorage.getItem(“key”).  This “key” would be “mode” or “previousPlace”.</p>

<h4>2.3.2 - Direct Data Collection</h4>
<p>Data is also, at points, request from the visitor.  There are three pages that do this “addSites”, “addOrg” and “addLinden”.  On these pages the visitor, obliquely, is asked to complete a task that directly changes the sites they are interacting with.  For example, “addOrg” visualises the current state of the collected melody “pseudo-neumatic” notation: black squares, similar to neumes, linked together with a black line.  This is only a visualisation of contour and doesn’t directly represent the melody degrees.  By clicking the visitor can add notes to the end of the pattern and the entire melody is then stored when the visitor presses the button labelled “Organalis”.  The page “addSites” asks the visitor to input sites of personal importance which later appear in pages that work with lists of site names.  “addLinden” shows a classic visualisation of an L-system “tree” (which in fact, uses a different set of rules to the data set this site uses, for simplicity).  Clicking on the button adds more loops to the system which enlarges and fleshes out the tree and simultaneously increments the loop number used for defining the L-system in other pages.</p>

<h3>2.4 - Musical Footsteps</h3>
<p>To access pages with musical content the visitor must navigate from category to another.  Staying within one category only loads “template” pages, environments with visual material only.  This structuring encourages visitors to explore the visual terrain in a simple way or to recombine their interactive experiences with new musical material. </p>
<p>Musical material is organised thus:</p>
<ul class = "lacList">
<li><b>Scatter</b>: spoken word and singing samples</li>
<li><b>Gather:</b> Organum and counterpoint</li>
<li><b>Cartography</b>: L-system synths</li>
<li><b>Repurpose</b>: musical and sound samples</li>
<li><b>atters</b>: combinations of the above</li>
</ul>
<p>See <b>Section 3</b> for more details.</p>
<p>he sound engine is chosen by the category of the page from which the visitor has just navigated.  If the visitor moves from a <b>Scatter</b> page to a <b>Gather</b> page the environment template will be form the <b>Gather</b> series of pages and the sound will be spoken word/sung samples.  This mechanism is not “dynamic” by which we mean that the program does not possess the ability to randomly combine any page with any sound source.  To make the musical interaction interesting the process must be hard coded into the specific pages.  We have therefore sacrificed “true” combinatory potential but we find the music to be more interesting, better organised and all in all more satisfying for the visitor.  The page choices are therefore somewhat deterministic: there are a set of potential pre-combined pages that the browser can call on moving from <b>Scatter</b> to <b>Gather</b>.  This was done both for the reason just outlined but also for aesthetic reasons.  True combination displayed far too much duplication: the pages were very similar and worked in very linear ways.  Each determinate combination therefore is coded to an aesthetic sensibility specific to the “task” at hand.  This still allows a large amount of variation depending on the choices of the user and, crucially, prevents the exploration of each page from becoming repetitive or overly familiar.</p>
<p><b>Tatters</b> combines pages and sound sources in ways that the normal navigation does not allow.  <b>Scatter</b> is usually only paired with <b>Gather</b> and <b>Repurpose</b> with <b>Cartography</b>.  <b>Tatters</b> opens these choices and pairs categories with thus far unfamiliar sound sources.</p>

<h2>3 - Music Machines</h2>
<p>This section will examine each of the musical processes in turn.</p>
<h3>3.1 - Scatter</h3>
<p>This category deals with spoken word and singing samples which deal with the semantic/symbolic modes of music making.  The principle “objects” (a JavaScript term for coded containers that have “properties” (data concerning the object) and “methods” (actions the object can perform)) are:</p>
<ul class = "lacList">
<li>fracture.js</li>
<li>samplerBands.js</li>
<li>songer.js</li>
</ul>
<p>These are also held in common with <b>Repurpose</b> pages and can be found in the “objects” folder of the site directory.</p>
<p>The object fracture is the main sound source.  This object loads sound files depending on its input arguments “type” and “cat” (category).  This allows the page to load either spoken word, sung, musical or sound recordings.  In “fracture” mode this object generates a sequence of data for playing the sound file such as “cue time”, “playback rate”, “pan”, “filter frequency”, “delay time” and so on.  When played in sequence the effect is a cutup “buffer” effect sequencer which plays repeat sample points of a file with filter, pan, and delay values for each trigger.  This effect is a JS implementation of the Glitchmachines plugin “Fracture” which does something similar.</p>
<p>In “sample” mode fracture simply plays a file at a designated start point also with options for pan and filter effects.  <b>Scatter</b> environments play with both of these modes for structural progression (see “case study 1”)</p>
<p>Sampler bands plays two sound files (loaded in a similar way to fracture) and cross fades between the two by sweeping through filter frequencies.  One file is attached to a highpass filter and the other to a lowpass both set to initial values of 20000hz.  The frequency value passed to both is the same (so a movement passes 500hz to both the lowpass and the highpass at the same time) which means that the sounds are filter cross faded.  This object is used primarily in pages that have a visual analogue to this process – for example in pages that blend two pictures together.  In the latter example the position of the blended zones determine the filter frequencies so that as one picture fades out so does the corresponding sound file.</p>
<p>Songer cuts up sound files in a more “songlike” manner.  This works like a less frenetic and eccentric version of fracture.  The sample phases are longer and processed to a lesser degree so that the “musical” content of the sample is foregrounded rather than its spectro-morphological characteristics.</p>
<p><u>Case Study 1: PicBlendFrac.js</u></p>
<p>This file can be found in the "PAGES" folder of active JavaScript files and is called by the file PicBlendFrac.html.  This page is in the <b>Gather</b> category with <b>Scatter</b> audio.  See also “picBlend1” and “picBlend2” JPEG files in the “diagrams” folder.</p>
<p>On loading the page browser checks session storage for previous page information.  These values determine the type of load animation used and which set of photos to choose from.  The file picChoice.js in the “objects” folder reads this session information and returns two randomly chosen filepaths to picBlendFrac to be loaded.  PicChoice contains sets of photos grouped into categories: this page can be called from different contexts (<b>Cartography</b> for example) and picChoice determines the appropriate set of images to be used.  For example if the user had chosen <b>Cartography</b> rather than <b>Gather</b> the page directs picChoice to choose images from the <b>Cartography</b> and Maps selection.  Session information also dictates the type of samples to be used: in this case the page loads spoken word or sung samples.  </p>
<p>An image is loaded.  Clicking the mouse make a 100 x 100 pixel section of the second image appear superimposed over the background.  In fact this second image has already been layered over the original with 100% transparency – the mouse click sets chosen section to 0% transparency.  Mouse clicking also triggers fracture to begin cycling through the sequence generated on load.  The two voices are controlled by right and left mouse buttons.  In conjunction with this, the add() method is called on fracture which adds a cue start time (between zero and sample length) to the sequence as long as the sequence is under sixteen values long.  Each click is counted, incrementing the mouseCount variable.  If this rises to the same value as the variable mouseRand, generated on load, the bpm of the facture sequence is randomly reset and the count values are reset to zero.  Releasing the mouse stops all audio.</p>
<p>A total number of “holes” is also counted.  This is tested against a similar random value and toggles a structural Boolean called fracState.  When fracState is “true” the above happens as normal.  When fracState is “false” the program switches from “fracture” mode to “play” mode an the samples are played without any buffer processing.  Mouse clicking determines the play head of the sampler and a further Boolean “playState” determines whether clicking changes filter or delay values when mouseCount equals mouseRand.  Simultaneously, the size of the newly visible sections of image is randomly calculated on each mousepress. </p>
<p>The final state is when both fracState and playState are “false” – this triggers the object melody.js to loop the melody stored in session.  Releasing the mouse alters the envelope and filter parameters of this melody.  When either of these states is altered the melody is stopped.</p>
<p>The toggling of these two states progresses three different structural regions with subregions that allow for parameter changing.  In addition, the program does not allow a cursor to be shown which frustrates the expected visual feedback.  The more of the second image is available the longer and more developed the fracture audio becomes and at certain points the highly processed samples are replaced with glimpses of their “original” state.  Aesthetically the audio-visual language is one of revealing, fragmentation and layering with a frustrated keyhole view of other images/sounds.</p>

<h3>3.2 - Gather</h3>
<p>These pages generate organum-like melodic phrases.  The two principle engines are </p>
<ul class = "lacList">
<li>organum.js</li>
<li>parallelOrganum.js</li>
<li>melody.js</li>
<li>orgChord.js</li>
</ul>
<p>All of these pages access the stored melody from session storage on load.  The melodies are then mapped to a specific mode determined by the previous page.  </p>
<p>Organum plays a cantus firmus that is harmonised by melodies randomly generated from the session melody.  Blank spaces are inserted into the melodies to make them more rhythmic and user interaction can rewrite, extend, reverse and change the octave of these sequences.  There is also the option to trigger each note individually or play the sequence at a certain bpm.  Parameters for synthesis are chose at random on page load.  As the user progresses through the pages the melody increases in length.  There is also the “alt cantus” which plays single note of the cantus firmus in a rhythm decided on load: this sequencer requires prompting before the next note is played.</p>
<p>Parallel organum works in a similar fashion to the above but harmonises the melodies in parallel fifths above and below the cantus firmus</p>
<ul class = "lacList">
<li>Melody simply plays the collected cantus firmus in a spatially distinct way</li>
<li>OrgChords plays a chord sequence based on the collected melody</li>
<li>The latter two objects are designed as structural foils to the either of the main music sources.</li>
</ul>

</p><u>Case Study 2: starsMoveOrganum.js</u></p>
<p>At page load the browser initialises the organum object and feeds it randomly selected bpm and octave information.  Organum then reads the melody stored in session and maps it to the mode also stored from navigation.  Finally the floral() method is called which harmonises the cantus firmus in two voices.  The length of the melody depends on the amount of the visitor has spent in the website but within the <b>Gather</b> pages is a page that allows the visitor to draw their own additions to the melody, presented in a pseudo-neumatic notation.  See “starsMoveOrganum” video in the “videos folder”</p>
<p>The setup() function draws one hundred stars on a black background.  Additionally, eighteen other coordinates are stored in variables for later drawing.  The mapper() function is then called which draws a constellation: nine stars are linked together in a line with each point also linked to a further point.  Mapper() is called every 25ms and on each call an increment is added to every drawn point.  This increment is calculated from the pmouse position which is the saved mouse position (in pixels) of the previous render frame.  This means that the increment is zero if the mouse is still and the faster the mouse is moved the faster the star positions are incremented.  The effect is to shift and warp the constellation around the screen as if every point is tied by an invisible string to the mouse cursor.</p>
<p>There are three music structure modes.  When the variable structure equals zero and the left mousebutton is pressed organum plays the “alt” cantus which is a rhythmic ostinato on one note and the mouse coordinates are saved.  The right button plays the other voice sequencers.  Releasing either button stops the voices which they initially triggered.  The canvas has been divided into four zones: if the current mouse position is in a different zone when released to when it was initially pressed the note position for the alt cantus is progressed to the next index.</p>
<p>Mouse clicks are recorded and trigger structure changes when they cross a random threshold decided on load.  When structure equals zero or one the cantus firmus and harmony function work the same as above.  When structure equals two the cantus no longer plays.  This has specific consequence for the mouse drag function.  Holding a mouse button and dragging changes the amplitude envelope and pan values of the synthesizer in different ways depending on the value of structure.  The mouse position at all times, regardless of dragging or clicking, controls the frequency values of three lowpass filters.</p>
<p>The effect of this page is a shifting and sliding star constellation.  The more violent the movements the more distended the stars become.  Tied to these movements are synth parameter changes and note triggering.  These two functions are somewhat at odds as the constellation warp induces an anxious, slightly seasick affect which inspires delicacy of movement while the synth requires more decisive movements to open the full spectrum of sounds and melody.  A balance (which does sometimes feel like actual balancing on a wobbly surface) between these two exploratory movements is required and the tension between the necessary tasks provides the backbone of the aesthetic experience.</p>

<h3>3.3 - Repurpose</h3>
<p>This category also uses sound recordings but focusses on musical and object recordings.  The principle instruments are the same as those used in <b>Scatter</b> (with the sample choice altered on page load).  Case study 3 examines how these mechanics are specific to these categories.</p>
<p><u>Case Study 3: mapWordSong.js</u></p>
<p>On this page the visitor is presented with a map on which they can draw sites and routes between them.  On page load a section of map is loaded to the full screen size and a single dot within a circle is drawn at a random position.  This site is named with a site name from one of four collections of sites.  Clicking the mouse draws new sites also with names from the same collection while simultaneously connecting the previous site to the newly created dot.  A right click changes the name collection and all of the rendered names while also redrawing the site positions.  The sites can be dragged by dragging the mouse.  A function is set to be called every two seconds which changes the colours of the site markers.  See “mapWordSong” video in the videos folder for a short demonstration.</p>
<p>The canvas is divided into four quadrants each of which controls a voice or selection of voices in the object songer.  Clicking in each quadrant starts or stops a determined set of voices.  Whenever a change in site collection is triggered these quadrants are designated with a new set of voices.  If the number of sites hits the upper limit (fifteen) the play mode of songer is swapped to simple playback.  Right clicking switches the sequencer rhythm from its primary pattern to its secondary.  Finally, if the number of site changes crosses over a predetermined threshold a pattern of playback rates is introduced into songer.  Previously, playback was limited to cue start times but within this specific play mode each trigger is defined by a playback rate.  Dragging the mouse adds new sequencer triggers and rate values to these patterns.  If the user has explored the <b>Cartography</b> pages thoroughly enough an opportunity to enter personal site names into the browser will have been offered.  These names are stored and appended to the site lists allowing them to be used alongside the initial names.</p>
<p>The effect is quite simple yet goes beyond a “mixing/djing” paradigm.  Drawing maps and routes over a scan of an OS map evokes a sense of rewriting landforms while also uncovering patterns and making connections between sites of significance.  This mechanic is combined with spatialised sample trigger which is directly linked to the shapes the visitor draws.  The samples used are not beat matched or key matched and as such will phase and clash eratically: it is up to the visitor to draw maps that bring their playback into a semblance of order.  Similarly, the visitor does not have complete control over the context as the structural points are defined randomly or are triggered after a random interval has passed.  Within this shifting situation of randomness and direct control there will be some moments that match up exactly and satisfyingly and others that collapse into mayhem.</p>

<h3>3.4 - Cartography</h3>
<p>In this section the sound sources are controlled by a Lindenmayer system.  This system stars with an “axiom” and a set of rules.  The program iterates over each element of the axiom and decides on an action based on the value of that element.  In this case symbols are used to decide whether to ascend or descend a semitone, tone, perfect fourth, perfect fifth, major or minor third.  The initial axiom can be altered to send the subsequent “sentence” down a different route.  The length (or “loops”) of the program are incremented each time the visitor selects a cartography page.  The rules are static meaning the melodies will bear a family resemblance to each other.  The main instruments are:</p>
<ul class = "lacList">
<li>lindenStrings.js - a “string trio”</li>
<li>lindenSampler.js – plays a three string samples </li>
<li>lindenAphex.js – an Aphex Twin inspired stereo sequencer</li>
</ul>
<p>In each of the above cases the note values (or playback rate) is controlled by the L-system sentence.  Sequence progression can be controlled by “internal” sequencers that are triggered, shortened/lengthened, sped up or slowed down by visitor interaction.  The exception is lindenAphex which is oriented more towards fast repetitions of one value which needs to be progressed by calling a method. </p>
<p>These instruments are joined by boards.js which makes a Boards of Canada-y style beat with processed drums and delay.  This is not strictly an L-system but uses a set of very simple binary rhythms (for example [1,0,1,0,] where 1 represents a trigger) that are added to in conjunction with additions to the L-system playbacks.</p>
<p><u>Case Study 4: textHighlightStrings.js</u></p>
<p>In this example sections of text disappear and are replaced when highlighted by the visitor.  See the video “textHighlightStrings” in the video folder for more information</p>
<p>he text is laid out like a prose poem and it may take some exploration before the mechanic of this page become apparent.  A secondary text is loaded into the page by the same algorithm that has previously been used to choose photos or samples.  This string is broken down into component words and stored in an array.  Whenever a user highlights a section of visible text the program creates a <span> html element around the selection and hides the text.  This triggers a timer which, on reaching its limit, calls the filler() function that replaces, in the gap, an appropriate amount of text from the “hidden” secondary text.  This second text is presented in a different font.</p>
<p>On pressing a mousebutton the first voice of the string trio is triggered.  Each subsequent click progresses the note along the L-system sentence.  When the filler() function is called the other two voices are triggered along with a detune value that is mapped to the size of the text selection.  This is not incremental and defaults to zero.  Dragging the mouse button changes the amplitude envelope of the synth: the left button changes attack and the right decay.</p>
<p>In a similar style to earlier pages this program also logs mouseclicks.  When this number passes over a threshold the structure variable, which decides how interaction will affect the sound source, is incremented.  The above scenario is true when structure equals zero: when structure equals one left mouseclicks trigger all three string voices at once and a narration starts to play.  Releasing he mousebutton stops the sample playback.</p>
<p>This page is rather meditative but also one of the more obscure environments.  It questions a visitor’s relationship to text and displays the given nature of fixed bodies of text by “hiding” in the disguise of an unalterable statement.  Slashing away at the text and finding new and meaningless additions behind it shows the fragile nature of original’s coherence.  Interacting with the musical elements moves the visitor’s attention away from the semantic meaning of the text and instead focusses it towards a more “sound object” approach where words become resources rather than vessels of meaning.  The samples intrude on this new viewpoint bringing focus back towards the now corrupted original as the two narratives mingle and confuse one another.</p>


<h2>References</h2>
<p>The Coding Train (2016), Coding Challenge #16: L-System Fractal Trees, 31/05, accessed last on 1/9/2020, available at: (https://www.youtube.com/watch?v=E1B4UoSQMFw).</p>
<p>The Coding Train (2016), Coding Challenge #24: Perlin Noise Flow Field, 27/06, accessed last on 1/9/2020, available at: (https://www.youtube.com/watch?v=E1B4UoSQMFw).</p>
<p>5.js, available at: (https://p5js.org/)</p>
<p>5.js on GitHub, available at: (https://github.com/processing/p5.js/)</p>
<p>WebAudio API, available at (https://github.com/WebAudio/web-audio-api)</p>
